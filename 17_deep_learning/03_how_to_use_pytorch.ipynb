{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch has been developed at the Facebook AI Research group led by Yann LeCunn and the first alpha version released in September 2016. It provides deep integration with Python libraries like Numpy that can be used to extend its functionality, strong GPU acceleration, and automatic differentiation using its autograd system. It provides more granular control than Keras through a lower-level API and is mainly used as a deep learning research platform but can also replace NumPy while enabling GPU computation.\n",
    "\n",
    "It employs eager execution, in contrast to the static computation graphs used by, e.g., Theano or TensorFlow. Rather than initially defining and compiling a network for fast but static execution, it relies on its autograd package for automatic differentiation of Tensor operations, i.e., it computes gradients ‘on the fly’ so that network structures can be partially modified more easily. This is called define-by-run, meaning that backpropagation is defined by how your code runs, which in turn implies that every single iteration can be different. The PyTorch documentation provides a detailed tutorial on this.\n",
    "\n",
    "- [PyTorch Documentation](https://pytorch.org/docs)\n",
    "- [PyTorch Tutorials](https://pytorch.org/tutorials)\n",
    "\n",
    "The resulting flexibility combined with an intuitive Python-first interface and speed of execution have contributed to its rapid rise in popularity and led to the development of numerous supporting libraries that extend its functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:17.492148Z",
     "start_time": "2020-03-14T23:29:17.490262Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.063353Z",
     "start_time": "2020-03-14T23:29:17.496356Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c6a694a9dc33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_circles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.064893Z",
     "start_time": "2020-03-14T23:29:17.497Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 2         # Input data dimensionality\n",
    "hidden_size = 3        # The number of nodes at the hidden layer\n",
    "num_classes = 2        # The number of output classes\n",
    "num_epochs = 20         # The number of times entire dataset is trained\n",
    "batch_size = 20        # The size of input data for one iteration\n",
    "learning_rate = 0.01  # The speed of convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.065486Z",
     "start_time": "2020-03-14T23:29:17.501Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset params\n",
    "N = 50000\n",
    "factor = 0.1\n",
    "noise = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.066074Z",
     "start_time": "2020-03-14T23:29:17.504Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "X, y = make_circles(\n",
    "    n_samples=N,\n",
    "    shuffle=False,\n",
    "    factor=factor,\n",
    "    noise=noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Torch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by converting the NumPy or pandas input data to torch Tensors. Conversion from and to Numpy is very straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.066715Z",
     "start_time": "2020-03-14T23:29:17.507Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.067285Z",
     "start_time": "2020-03-14T23:29:17.510Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tensor.shape, y_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Torch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these PyTorch Tensor to instantiate first a TensorDataset and, in a second step, a DataLoader that includes information about batch_size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.067811Z",
     "start_time": "2020-03-14T23:29:17.513Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = utils.TensorDataset(X_tensor,y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Torch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.068378Z",
     "start_time": "2020-03-14T23:29:17.515Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = utils.DataLoader(dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch defines a NN architecture using the Net() class. The central element is the forward function. autograd automatically defines the corresponding backward function that computes the gradients. \n",
    "\n",
    "Any legal Tensor operation is fair game for the forward function, providing a log of design flexibility. In our simple case, we just link the Tensor through functional input-output relations after initializing their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.068927Z",
     "start_time": "2020-03-14T23:29:17.519Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.logistic = nn.LogSigmoid()                          \n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: stacking each layer together\"\"\"\n",
    "        out = self.fc1(x)\n",
    "        out = self.logistic(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.069531Z",
     "start_time": "2020-03-14T23:29:17.522Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.070021Z",
     "start_time": "2020-03-14T23:29:17.524Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.070478Z",
     "start_time": "2020-03-14T23:29:17.526Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.070930Z",
     "start_time": "2020-03-14T23:29:17.528Z"
    }
   },
   "outputs": [],
   "source": [
    "list(net.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable GPU processing, you can use net.cuda(). See Pytorch docs for placing Tensors on CPU and/or one or more GPU units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.071455Z",
     "start_time": "2020-03-14T23:29:17.532Z"
    }
   },
   "outputs": [],
   "source": [
    "# net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define a loss function and the optimizer, using some of the built-in options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.071925Z",
     "start_time": "2020-03-14T23:29:17.534Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.072515Z",
     "start_time": "2020-03-14T23:29:17.538Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training consists in an outer loop for each epoch, i.e., each pass over the training data, and an inner loop over the batches produced by the DataLoader. That executes the forward and backward passes of the learning algorithm. Some care needs to be taken to adjust data types to the requirements of the various objects and functions, e.g. labels need to be integers and the features should be of type floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.073565Z",
     "start_time": "2020-03-14T23:29:17.542Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (features, label) in enumerate(dataloader):\n",
    "        \n",
    "        features = Variable(features.float())         \n",
    "        label = Variable(label.long())\n",
    "\n",
    "        # Initialize the hidden weights\n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        # Forward pass: compute output given features\n",
    "        outputs = net(features)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, label)\n",
    "        # Backward pass: compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting losses in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example that uses the `livelossplot` package to plot losses throughout the training process as provided by Keras out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.074144Z",
     "start_time": "2020-03-14T23:29:17.545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liveloss = PlotLosses()\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    logs = {}\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0    \n",
    "    for i, (features, label) in enumerate(dataloader):\n",
    "        \n",
    "        features = Variable(features.float())         \n",
    "        label = Variable(label.long())\n",
    "\n",
    "        # Intialize the hidden weight to all zeros\n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        # Forward pass: compute the output class given a image\n",
    "        outputs = net(features)\n",
    "        \n",
    "        # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss = criterion(outputs, label)\n",
    "        # Backward pass: compute the weight\n",
    "        loss.backward()\n",
    "        # Optimizer: update the weights of hidden nodes\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.detach() * features.size(0)\n",
    "        running_corrects += torch.sum(preds == label.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        epoch_acc = running_corrects.float() / len(dataloader.dataset)        \n",
    "        logs['log loss'] = loss.item()\n",
    "        logs['accuracy'] = epoch_acc.item()\n",
    "\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain predictions from our trained model, we pass it feature data and convert the prediction to a Numpy array. We get softmax probabilities for each of the two classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.074749Z",
     "start_time": "2020-03-14T23:29:17.548Z"
    }
   },
   "outputs": [],
   "source": [
    "test_value = Variable(torch.from_numpy(X)).float()\n",
    "prediction = net(test_value).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.075339Z",
     "start_time": "2020-03-14T23:29:17.550Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, we can proceed as before to compute loss metrics or visualize the result that again reproduces a version of the decision boundary we found above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.075880Z",
     "start_time": "2020-03-14T23:29:17.553Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y, y_pred=np.argmax(prediction, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.076764Z",
     "start_time": "2020-03-14T23:29:17.555Z"
    }
   },
   "outputs": [],
   "source": [
    "n_vals = 200\n",
    "x1 = np.linspace(-1.5, 1.5, num=n_vals)\n",
    "x2 = np.linspace(-1.5, 1.5, num=n_vals)\n",
    "xx, yy = np.meshgrid(x1, x2)  # create the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.077480Z",
     "start_time": "2020-03-14T23:29:17.558Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.array([xx.ravel(), yy.ravel()]).T\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.078152Z",
     "start_time": "2020-03-14T23:29:17.560Z"
    }
   },
   "outputs": [],
   "source": [
    "zz = net(Variable(X_test).float()).data.numpy()\n",
    "zz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.078884Z",
     "start_time": "2020-03-14T23:29:17.563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a color map to show the classification colors of each grid point\n",
    "cmap = ListedColormap([sns.xkcd_rgb[\"pale red\"],\n",
    "                       sns.xkcd_rgb[\"denim blue\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T23:29:18.079465Z",
     "start_time": "2020-03-14T23:29:17.565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the classification plane with decision boundary and input samples\n",
    "plt.contourf(xx, yy, np.argmax(zz, axis=1).reshape(n_vals, -1), cmap=cmap, alpha=.25)\n",
    "\n",
    "# Plot both classes on the x1, x2 plane\n",
    "data = pd.DataFrame(X, columns=['$x_1$', '$x_2$']).assign(Class=pd.Series(y).map({0:'negative', 1:'positive'}))\n",
    "sns.scatterplot(x='$x_1$', y='$x_2$', hue='Class', data=data, style=y, markers=['_', '+'], legend=False)\n",
    "plt.title('Decision Boundary')\n",
    "plt.savefig('boundary', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
