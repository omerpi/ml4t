{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains information on downloading the Quandl Wiki stock prices and a few other sources that we use throughout the book. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:37:57.984384Z",
     "start_time": "2020-04-18T21:37:57.977788Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:37:58.503535Z",
     "start_time": "2020-04-18T21:37:58.241635Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Store path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify path if you would like to store the data elsewhere and change the notebooks accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:38:00.010989Z",
     "start_time": "2020-04-18T21:38:00.005533Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = Path('assets.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quandl Wiki Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quandl](https://www.quandl.com/) makes available a [dataset](https://www.quandl.com/databases/WIKIP/documentation) with stock prices, dividends and splits for 3000 US publicly-traded companies. Quandl decided to discontinue support in favor of its commercial offerings but the historical data are still useful to demonstrate the application of the machine learning solutions in the book, just ensure you implement your own algorithms on current data.\n",
    "\n",
    "> As of April 11, 2018 this data feed is no longer actively supported by the Quandl community. We will continue to host this data feed on Quandl, but we do not recommend using it for investment or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Follow the instructions to create a free [Quandl]([Quandl](https://www.quandl.com/)) account\n",
    "2. [Download](https://www.quandl.com/databases/WIKIP/usage/export) the entire WIKI/PRICES data\n",
    "3. Extract the .zip file,\n",
    "4. Move to this directory and rename to wiki_prices.csv\n",
    "5. Run the below code to store in fast HDF format (see [Chapter 02 on Market & Fundamental Data](../02_market_and_fundamental_data) for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv('wiki_prices.csv',\n",
    "                 parse_dates=['date'],\n",
    "                 index_col=['date', 'ticker'],\n",
    "                 infer_datetime_format=True)\n",
    "     .sort_index())\n",
    "\n",
    "print(df.info(null_counts=True))\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('quandl/wiki/prices', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki Prices Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of writing, the following instructions no longer work because Quandl changed its API:\n",
    "\n",
    "> 1. Follow the instructions to create a free [Quandl]([Quandl](https://www.quandl.com/)) account if you haven't done so yet\n",
    "> 2. Find link to download wiki metadata under Companies](https://www.quandl.com/databases/WIKIP/documentation) or use the download link with your API_KEY: https://www.quandl.com/api/v3/databases/WIKI/metadata?api_key=<API_KEY>\n",
    "> 3. Extract the .zip file,\n",
    "> 4. Move to this directory and rename to wiki_stocks.csv\n",
    "> 5. Run the following code to store in fast HDF format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, load the file `wiki_stocks.csv` as described and store in HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3199 entries, 0 to 3198\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   code    3199 non-null   object\n",
      " 1   name    3199 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 50.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wiki_stocks.csv')\n",
    "# no longer needed\n",
    "# df = pd.concat([df.loc[:, 'code'].str.strip(),\n",
    "#                 df.loc[:, 'name'].str.split('(', expand=True)[0].str.strip().to_frame('name')], axis=1)\n",
    "\n",
    "print(df.info(null_counts=True))\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('quandl/wiki/stocks', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads historical S&P 500 prices from FRED (only last 10 years of daily data is freely available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2608 entries, 2010-02-16 to 2020-02-13\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   close   2517 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 40.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = web.DataReader(name='SP500', data_source='fred', start=2009).squeeze().to_frame('close')\n",
    "print(df.info())\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('sp500/fred', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, download S&P500 data from [stooq.com](https://stooq.com/q/?s=%5Espx&c=1d&t=l&a=lg&b=0); at the time of writing the data was available since 1789. You can switch from Polish to English on the lower right-hand side.\n",
    "\n",
    "We store the data from 1950-2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17700 entries, 1950-01-03 to 2019-12-31\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    17700 non-null  float64\n",
      " 1   high    17700 non-null  float64\n",
      " 2   low     17700 non-null  float64\n",
      " 3   close   17700 non-null  float64\n",
      " 4   volume  17700 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 829.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sp500_stooq = (pd.read_csv('^spx_d.csv', index_col=0,\n",
    "                     parse_dates=True).loc['1950':'2019'].rename(columns=str.lower))\n",
    "print(sp500_stooq.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('sp500/sp500_stooq', sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 Constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads the current S&P 500 constituents from [Wikipedia](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 505 entries, 3M Company to Zoetis\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   name               505 non-null    object\n",
      " 1   gics_sector        505 non-null    object\n",
      " 2   gics_sub_industry  505 non-null    object\n",
      " 3   location           505 non-null    object\n",
      " 4   first_added        403 non-null    object\n",
      " 5   cik                505 non-null    int64 \n",
      " 6   founded            191 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 31.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "df = pd.read_html(url, header=0)[0]\n",
    "df.columns = ['name', 'ticker', 'sec_filings', 'gics_sector', 'gics_sub_industry',\n",
    "              'location', 'first_added', 'cik', 'founded']\n",
    "df = df.drop('sec_filings', axis=1).set_index('ticker')\n",
    "print(df.info())\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('sp500/stocks', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata on US-traded companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following downloads several attributes for [companies](https://www.nasdaq.com/screening/companies-by-name.aspx) traded on NASDAQ, AMEX and NYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6986 entries, TXG to ZYME\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   name       6986 non-null   object \n",
      " 1   lastsale   6859 non-null   float64\n",
      " 2   marketcap  5913 non-null   object \n",
      " 3   ipoyear    3222 non-null   float64\n",
      " 4   sector     5347 non-null   object \n",
      " 5   industry   5347 non-null   object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 382.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange={}&render=download'\n",
    "exchanges = ['NASDAQ', 'AMEX', 'NYSE']\n",
    "df = pd.concat([pd.read_csv(url.format(ex)) for ex in exchanges]).dropna(how='all', axis=1)\n",
    "df = df.rename(columns=str.lower).set_index('symbol').drop('summary quote', axis=1)\n",
    "df = df[~df.index.duplicated()]\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lastsale</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>ipoyear</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TXG</th>\n",
       "      <td>10x Genomics, Inc.</td>\n",
       "      <td>86.7700</td>\n",
       "      <td>$8.34B</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>Biotechnology: Laboratory Analytical Instruments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YI</th>\n",
       "      <td>111, Inc.</td>\n",
       "      <td>5.6300</td>\n",
       "      <td>$464.19M</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Medical/Nursing Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIH</th>\n",
       "      <td>1347 Property Insurance Holdings, Inc.</td>\n",
       "      <td>5.5150</td>\n",
       "      <td>$33.64M</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Property-Casualty Insurers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIHPP</th>\n",
       "      <td>1347 Property Insurance Holdings, Inc.</td>\n",
       "      <td>27.3236</td>\n",
       "      <td>$19.13M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Property-Casualty Insurers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TURN</th>\n",
       "      <td>180 Degree Capital Corp.</td>\n",
       "      <td>2.2000</td>\n",
       "      <td>$68.47M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Finance/Investors Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  lastsale marketcap  ipoyear         sector                                          industry\n",
       "symbol                                                                                                                                      \n",
       "TXG                         10x Genomics, Inc.   86.7700    $8.34B   2019.0  Capital Goods  Biotechnology: Laboratory Analytical Instruments\n",
       "YI                                   111, Inc.    5.6300  $464.19M   2018.0    Health Care                          Medical/Nursing Services\n",
       "PIH     1347 Property Insurance Holdings, Inc.    5.5150   $33.64M   2014.0        Finance                        Property-Casualty Insurers\n",
       "PIHPP   1347 Property Insurance Holdings, Inc.   27.3236   $19.13M      NaN        Finance                        Property-Casualty Insurers\n",
       "TURN                  180 Degree Capital Corp.    2.2000   $68.47M      NaN        Finance                        Finance/Investors Services"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert market cap information to numerical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market cap is provided as strings so we need to convert it to numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    3431\n",
       "B    2476\n",
       "0       3\n",
       "5       1\n",
       "1       1\n",
       "6       1\n",
       "Name: suffix, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcap = df[['marketcap']].dropna()\n",
    "mcap['suffix'] = mcap.marketcap.str[-1]\n",
    "mcap.suffix.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only values with value units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5907 entries, TXG to ZYME\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   marketcap  5907 non-null   float64\n",
      " 1   suffix     5907 non-null   object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 298.4+ KB\n"
     ]
    }
   ],
   "source": [
    "mcap = mcap[mcap.suffix.str.endswith(('B', 'M'))]\n",
    "mcap.marketcap = pd.to_numeric(mcap.marketcap.str[1:-1])\n",
    "mcaps = {'M': 1e6, 'B': 1e9}\n",
    "for symbol, factor in mcaps.items():\n",
    "    mcap.loc[mcap.suffix == symbol, 'marketcap'] *= factor\n",
    "mcap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                5,907\n",
       "mean         8,256,303,052\n",
       "std         44,375,841,137\n",
       "min              1,040,000\n",
       "10%             31,036,000\n",
       "20%             88,216,000\n",
       "30%            197,041,999\n",
       "40%            332,130,000\n",
       "50%            601,250,000\n",
       "60%          1,130,000,000\n",
       "70%          2,271,999,999\n",
       "80%          4,850,000,000\n",
       "90%         14,230,000,000\n",
       "max      1,421,460,000,000\n",
       "Name: marketcap, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['marketcap'] = mcap.marketcap\n",
    "df.marketcap.describe(percentiles=np.arange(.1, 1, .1).round(1)).apply(lambda x: f'{int(x):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `us_equities_meta_data.csv` contains a version of the data used for many of the examples. Load using \n",
    "```\n",
    "data = pd.read_csv('us_equities_meta_data.csv')\n",
    "```\n",
    "and proceed to store in HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/.pyenv/versions/miniconda3-latest/envs/ml4t/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['name', 'sector', 'industry'], dtype='object')]\n",
      "\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('us_equities/stocks', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stooq Historical Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the below downloading details may change at any time as Stooq updates their website; if you encounter errors, please inspect their website and raise a GitHub issue to let us know so we can update the information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download price data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download **price data** for the selected combination of asset class, market and frequency from [the Stooq website](https://stooq.com/db/h/)\n",
    "2. Store the result under `stooq` using the preferred folder structure outlined on the website. It has the structure: `/data/freq/market/asset_class`, such as `/data/daily/us/nasdaq etfs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T20:43:47.976210Z",
     "start_time": "2020-04-18T20:43:47.968770Z"
    }
   },
   "source": [
    "Add the corresponding **symbols**, i.e., tickers and names by following the directory tree on the same site. You can also adapt the following code snippet using the appropriate asset code that you find by inspecting the url; this example works for NASDAQ ETFs that have code `g=69`:\n",
    "```python\n",
    "df = pd.read_csv('https://stooq.com/db/l/?g=69', sep='        ').apply(lambda x: x.str.strip())\n",
    "df.columns = ['ticker', 'name']\n",
    "df.drop_duplicates('ticker').to_csv('stooq/data/tickers/us/nasdaq etfs.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T22:18:38.085259Z",
     "start_time": "2020-04-18T22:18:38.082084Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_dict = {\n",
    "    ('jp', 'tse etfs'): 34,\n",
    "    ('jp', 'tse stocks'): 32,\n",
    "    ('us', 'nasdaq etfs'): 69,\n",
    "    ('us', 'nasdaq stocks'): 27,\n",
    "    ('us', 'nyse etfs'): 70,\n",
    "    ('us', 'nyse stocks'): 28,\n",
    "    ('us', 'nysemkt stocks'): 26\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T22:18:42.534140Z",
     "start_time": "2020-04-18T22:18:38.536304Z"
    }
   },
   "outputs": [],
   "source": [
    "for (market, asset_class), code in metadata_dict.items():\n",
    "    df = pd.read_csv(f'https://stooq.com/db/l/?g={code}', sep='        ').apply(lambda x: x.str.strip())\n",
    "    df.columns = ['ticker', 'name']\n",
    "    df.drop_duplicates('ticker').dropna().to_csv(f'stooq/data/tickers/{market}/{asset_class}.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store price data in HDF5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up loading, we store the price data in HDF format. The function `get_stooq_prices_and_symbols` loads data assuming the directory structure described above and takes the following arguments:\n",
    "- frequency (see Stooq website for options as these may change; default is `daily`\n",
    "- market (default: `us`), and \n",
    "- asset class (default: `nasdaq etfs`.\n",
    "\n",
    "It removes files that do not have data or do not appear in the corresponding list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T22:26:51.977567Z",
     "start_time": "2020-04-18T22:26:51.970132Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_stooq_prices_and_tickers(frequency='daily',\n",
    "                                 market='us',\n",
    "                                 asset_class='nasdaq etfs'):\n",
    "    prices = []\n",
    "    stooq_path = Path('stooq', 'data')\n",
    "    tickers = (pd.read_csv(stooq_path / 'tickers' / market / f'{asset_class}.csv'))\n",
    "\n",
    "    if frequency in ['5 min', 'hourly']:\n",
    "        parse_dates = [['date', 'time']]\n",
    "        date_label = 'date_time'\n",
    "    else:\n",
    "        parse_dates = ['date']\n",
    "        date_label = 'date'\n",
    "    names = ['ticker', 'freq', 'date', 'time', \n",
    "             'open', 'high', 'low', 'close','volume', 'openint']\n",
    "    usecols = ['ticker', 'open', 'high', 'low', 'close', 'volume'] + parse_dates\n",
    "    path = stooq_path / frequency / market / asset_class\n",
    "    files = path.glob('**/*.txt')\n",
    "    for i, file in enumerate(files, 1):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        if file.stem not in set(tickers.ticker.str.lower()):\n",
    "            print(file.stem, 'not available')\n",
    "            file.unlink()\n",
    "        else:\n",
    "            try:\n",
    "                df = (pd.read_csv(\n",
    "                    file,\n",
    "                    names=names,\n",
    "                    usecols=usecols,\n",
    "                    header=0,\n",
    "                    parse_dates=parse_dates))\n",
    "                prices.append(df)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print('\\tdata missing', file.stem)\n",
    "                file.unlink()\n",
    "\n",
    "    prices = (pd.concat(prices, ignore_index=True)\n",
    "              .rename(columns=str.lower)\n",
    "              .set_index(['ticker', date_label])\n",
    "              .apply(lambda x: pd.to_numeric(x, errors='coerce')))\n",
    "    return prices, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using US equities and ETFs in [Chapter 9](../09_time_series_models) and and Japanese equities in [Chapter 11](../11_decision_trees_random_forests). The following code collects the price data for the period 2000-2019 and stores it with the corresponding symbols in the global `assets.h5` store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T22:29:18.339279Z",
     "start_time": "2020-04-18T22:26:57.300039Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tse stocks\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "\n",
      "No. of observations per asset\n",
      "count    3685.000000\n",
      "mean     2804.802714\n",
      "std      1175.998776\n",
      "min         1.000000\n",
      "25%      2148.000000\n",
      "50%      3041.000000\n",
      "75%      3621.000000\n",
      "max      4905.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 10335698 entries, ('1301.JP', Timestamp('2005-03-22 00:00:00')) to ('9997.JP', Timestamp('2019-12-30 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count     Dtype  \n",
      "---  ------  --------------     -----  \n",
      " 0   open    10335698 non-null  float64\n",
      " 1   high    10335698 non-null  float64\n",
      " 2   low     10335698 non-null  float64\n",
      " 3   close   10335698 non-null  float64\n",
      " 4   volume  10335698 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 433.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3715 entries, 0 to 3714\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  3715 non-null   object\n",
      " 1   name    3715 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 58.2+ KB\n",
      "None\n",
      "\n",
      " nasdaq etfs\n",
      "\n",
      "No. of observations per asset\n",
      "count     170.000000\n",
      "mean     2239.335294\n",
      "std       776.489780\n",
      "min       995.000000\n",
      "25%      1654.000000\n",
      "50%      2184.500000\n",
      "75%      2807.500000\n",
      "max      5031.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 380687 entries, ('AAXJ.US', Timestamp('2008-08-15 00:00:00')) to ('ZIV.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    380687 non-null  float64\n",
      " 1   high    380687 non-null  float64\n",
      " 2   low     380687 non-null  float64\n",
      " 3   close   380687 non-null  float64\n",
      " 4   volume  380687 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 16.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  175 non-null    object\n",
      " 1   name    175 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "\n",
      " nasdaq stocks\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "\n",
      "No. of observations per asset\n",
      "count    3216.000000\n",
      "mean     1999.364428\n",
      "std      1508.628005\n",
      "min         1.000000\n",
      "25%       518.000000\n",
      "50%      1622.500000\n",
      "75%      3716.000000\n",
      "max      5031.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 6429956 entries, ('AACG.US', Timestamp('2008-01-28 00:00:00')) to ('ZYXI.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    6429956 non-null  float64\n",
      " 1   high    6429956 non-null  float64\n",
      " 2   low     6429956 non-null  float64\n",
      " 3   close   6429956 non-null  float64\n",
      " 4   volume  6429956 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 269.9+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3401 entries, 0 to 3400\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  3401 non-null   object\n",
      " 1   name    3401 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 53.3+ KB\n",
      "None\n",
      "\n",
      " nyse etfs\n",
      "500\n",
      "1000\n",
      "\n",
      "No. of observations per asset\n",
      "count    1038.000000\n",
      "mean     2452.026012\n",
      "std      1001.442313\n",
      "min         2.000000\n",
      "25%      1669.250000\n",
      "50%      2550.000000\n",
      "75%      3298.500000\n",
      "max      3738.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2545203 entries, ('AADR.US', Timestamp('2010-07-21 00:00:00')) to ('ZSL.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    2545203 non-null  float64\n",
      " 1   high    2545203 non-null  float64\n",
      " 2   low     2545203 non-null  float64\n",
      " 3   close   2545203 non-null  float64\n",
      " 4   volume  2545203 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 106.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1047 entries, 0 to 1046\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  1047 non-null   object\n",
      " 1   name    1047 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 16.5+ KB\n",
      "None\n",
      "\n",
      " nyse stocks\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "\n",
      "No. of observations per asset\n",
      "count    3831.000000\n",
      "mean     2072.182198\n",
      "std      1577.359114\n",
      "min         1.000000\n",
      "25%       563.000000\n",
      "50%      1695.000000\n",
      "75%      3737.000000\n",
      "max      5031.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 7938530 entries, ('A.US', Timestamp('2000-01-03 00:00:00')) to ('ZYME.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    7938530 non-null  float64\n",
      " 1   high    7938530 non-null  float64\n",
      " 2   low     7938530 non-null  float64\n",
      " 3   close   7938530 non-null  float64\n",
      " 4   volume  7938530 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 333.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3937 entries, 0 to 3936\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  3937 non-null   object\n",
      " 1   name    3937 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 61.6+ KB\n",
      "None\n",
      "\n",
      " nysemkt stocks\n",
      "\n",
      "No. of observations per asset\n",
      "count     296.000000\n",
      "mean     2592.023649\n",
      "std      1280.843185\n",
      "min         4.000000\n",
      "25%      1505.000000\n",
      "50%      3293.500000\n",
      "75%      3717.250000\n",
      "max      5029.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 767239 entries, ('AAMC.US', Timestamp('2012-12-13 00:00:00')) to ('ZOM.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    767239 non-null  float64\n",
      " 1   high    767239 non-null  float64\n",
      " 2   low     767239 non-null  float64\n",
      " 3   close   767239 non-null  float64\n",
      " 4   volume  767239 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 32.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  304 non-null    object\n",
      " 1   name    304 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load some Japanese and all US assets for 2000-2019\n",
    "markets = {'jp': ['tse stocks'],\n",
    "           'us': ['nasdaq etfs', 'nasdaq stocks', 'nyse etfs', 'nyse stocks', 'nysemkt stocks']\n",
    "          }\n",
    "frequency = 'daily'\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "for market, asset_classes in markets.items():\n",
    "    for asset_class in asset_classes:\n",
    "        print(f'\\n{asset_class}')\n",
    "        prices, tickers = get_stooq_prices_and_tickers(frequency=frequency, \n",
    "                                                       market=market, \n",
    "                                                       asset_class=asset_class)\n",
    "        \n",
    "        prices = prices.sort_index().loc[idx[:, '2000': '2019'], :]\n",
    "        names = prices.index.names\n",
    "        prices = (prices\n",
    "                  .reset_index()\n",
    "                  .drop_duplicates()\n",
    "                  .set_index(names)\n",
    "                  .sort_index())\n",
    "        \n",
    "        print('\\nNo. of observations per asset')\n",
    "        print(prices.groupby('ticker').size().describe())\n",
    "        key = f'stooq/{market}/{asset_class.replace(\" \", \"/\")}/'\n",
    "        \n",
    "        print(prices.info(null_counts=True))\n",
    "        \n",
    "        prices.to_hdf(DATA_STORE, key + 'prices', format='t')\n",
    "        \n",
    "        print(tickers.info())\n",
    "        tickers.to_hdf(DATA_STORE, key + 'tickers', format='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bond Price Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads several bond indexes from the Federal Reserve Economic Data service ([FRED](https://fred.stlouisfed.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities = {'BAMLCC0A0CMTRIV'   : 'US Corp Master TRI',\n",
    "              'BAMLHYH0A0HYM2TRIV': 'US High Yield TRI',\n",
    "              'BAMLEMCBPITRIV'    : 'Emerging Markets Corporate Plus TRI',\n",
    "              'GOLDAMGBD228NLBM'  : 'Gold (London, USD)',\n",
    "              'DGS10'             : '10-Year Treasury CMR',\n",
    "              }\n",
    "\n",
    "df = web.DataReader(name=list(securities.keys()), data_source='fred', start=2000)\n",
    "df = df.rename(columns=securities).dropna(how='all').resample('B').mean()\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('fred/assets', df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
