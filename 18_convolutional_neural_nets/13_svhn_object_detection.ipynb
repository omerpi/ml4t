{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Street View House Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to build a deep CNN using Kerasâ€™ functional API to generate multiple outputs: one to predict how many digits are present, and five for the value of each in the order they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.347230Z",
     "start_time": "2020-03-22T21:25:51.081401Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout, \n",
    "                                     BatchNormalization, Activation, Concatenate)\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T23:07:32.506023Z",
     "start_time": "2020-03-22T23:07:32.499273Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.355883Z",
     "start_time": "2020-03-22T21:25:52.350750Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('images', 'svhn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.370288Z",
     "start_time": "2020-03-22T21:25:52.358916Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "SEQ_LENGTH = 4\n",
    "N_CLASSES = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.442665Z",
     "start_time": "2020-03-22T21:25:52.371244Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.load(DATA_PATH / 'X_train.npy')\n",
    "y_train = np.load(DATA_PATH / 'y_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the rare cases of 5-digit house numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.501929Z",
     "start_time": "2020-03-22T21:25:52.443677Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train[y_train[:, 0] < 5]\n",
    "y_train = y_train[y_train[:, 0] < 5, :5]\n",
    "y_train[:, 0] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.529700Z",
     "start_time": "2020-03-22T21:25:52.502880Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.load(DATA_PATH / 'X_test.npy')\n",
    "y_test = np.load(DATA_PATH / 'y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.555629Z",
     "start_time": "2020-03-22T21:25:52.530595Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = X_test[y_test[:, 0] < 5]\n",
    "y_test = y_test[y_test[:, 0] < 5, :5]\n",
    "y_test[:, 0] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.564137Z",
     "start_time": "2020-03-22T21:25:52.557093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    10\n",
       "2    11\n",
       "3    11\n",
       "4    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.569090Z",
     "start_time": "2020-03-22T21:25:52.566078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33392, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks](https://arxiv.org/abs/1312.6082), Goodfellow, et al, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.577055Z",
     "start_time": "2020-03-22T21:25:52.569825Z"
    }
   },
   "outputs": [],
   "source": [
    "digit_pos = {1: [4, 14], 2: [14, 25], 3: [25, 36], 4: [36, 47]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.584487Z",
     "start_time": "2020-03-22T21:25:52.577997Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    n_digits_pred = K.argmax(y_pred[:, :SEQ_LENGTH], axis=1)\n",
    "\n",
    "    digit_preds = {}\n",
    "    for digit, (start, end) in digit_pos.items():\n",
    "        digit_preds[digit] = K.argmax(y_pred[:, start:end], axis=1)\n",
    "    preds = tf.dtypes.cast(tf.stack((n_digits_pred,\n",
    "                                     digit_preds[1],\n",
    "                                     digit_preds[2],\n",
    "                                     digit_preds[3],\n",
    "                                     digit_preds[4]), axis=1), tf.float32)\n",
    "\n",
    "    return K.mean(K.sum(tf.dtypes.cast(K.equal(y_true, preds), tf.int64), axis=1) / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:52.592227Z",
     "start_time": "2020-03-22T21:25:52.585305Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_entropy(y_true, y_pred):\n",
    "    cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    n_digits = y_pred[:, :SEQ_LENGTH]\n",
    "\n",
    "    digits = {}\n",
    "    for digit, (start, end) in digit_pos.items():\n",
    "        digits[digit] = y_pred[:, start:end]\n",
    "    return (cce(y_true[:, 0], n_digits) +\n",
    "            cce(y_true[:, 1], digits[1]) +\n",
    "            cce(y_true[:, 2], digits[2]) +\n",
    "            cce(y_true[:, 3], digits[3]) +\n",
    "            cce(y_true[:, 4], digits[4])) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:53.473185Z",
     "start_time": "2020-03-22T21:25:52.593089Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "vgg16.trainable = False\n",
    "x = vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "n_digits = Dense(SEQ_LENGTH, activation='softmax', name='n_digits')(x)\n",
    "digit1 = Dense(N_CLASSES-1, activation='softmax', name='d1')(x)\n",
    "digit2 = Dense(N_CLASSES, activation='softmax', name='d2')(x)\n",
    "digit3 = Dense(N_CLASSES, activation='softmax', name='d3')(x)\n",
    "digit4 = Dense(N_CLASSES, activation='softmax', name='d4')(x)\n",
    "predictions = Concatenate()([n_digits, digit1, digit2, digit3, digit4])\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:53.539835Z",
     "start_time": "2020-03-22T21:25:53.474037Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=weighted_entropy,\n",
    "              metrics=[weighted_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the model produces five distinct outputs that we can evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:53.542558Z",
     "start_time": "2020-03-22T21:25:53.540682Z"
    }
   },
   "outputs": [],
   "source": [
    "svhn_path = 'models/svhn.cnn.weights.best.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=svhn_path, \n",
    "                               verbose=1, \n",
    "                               monitor='val_weighted_accuracy',\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:53.550865Z",
     "start_time": "2020-03-22T21:25:53.543359Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_weighted_accuracy', \n",
    "                               patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:25:53.563428Z",
     "start_time": "2020-03-22T21:25:53.551695Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:02.315260Z",
     "start_time": "2020-03-22T21:25:53.564358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30052 samples, validate on 3340 samples\n",
      "Epoch 1/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 1.0651 - weighted_accuracy: 0.6415\n",
      "Epoch 00001: val_weighted_accuracy improved from -inf to 0.67581, saving model to models/svhn.cnn.weights.best.hdf5\n",
      "30052/30052 [==============================] - 141s 5ms/sample - loss: 1.0652 - weighted_accuracy: 0.6415 - val_loss: 0.9635 - val_weighted_accuracy: 0.6758\n",
      "Epoch 2/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.9256 - weighted_accuracy: 0.6839\n",
      "Epoch 00002: val_weighted_accuracy improved from 0.67581 to 0.68956, saving model to models/svhn.cnn.weights.best.hdf5\n",
      "30052/30052 [==============================] - 137s 5ms/sample - loss: 0.9256 - weighted_accuracy: 0.6839 - val_loss: 0.9170 - val_weighted_accuracy: 0.6896\n",
      "Epoch 3/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.8801 - weighted_accuracy: 0.6991\n",
      "Epoch 00003: val_weighted_accuracy improved from 0.68956 to 0.69429, saving model to models/svhn.cnn.weights.best.hdf5\n",
      "30052/30052 [==============================] - 138s 5ms/sample - loss: 0.8801 - weighted_accuracy: 0.6991 - val_loss: 0.9053 - val_weighted_accuracy: 0.6943\n",
      "Epoch 4/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.8440 - weighted_accuracy: 0.7108\n",
      "Epoch 00004: val_weighted_accuracy improved from 0.69429 to 0.69815, saving model to models/svhn.cnn.weights.best.hdf5\n",
      "30052/30052 [==============================] - 138s 5ms/sample - loss: 0.8440 - weighted_accuracy: 0.7108 - val_loss: 0.9034 - val_weighted_accuracy: 0.6982\n",
      "Epoch 5/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.8188 - weighted_accuracy: 0.7188\n",
      "Epoch 00005: val_weighted_accuracy did not improve from 0.69815\n",
      "30052/30052 [==============================] - 137s 5ms/sample - loss: 0.8189 - weighted_accuracy: 0.7187 - val_loss: 0.9061 - val_weighted_accuracy: 0.6963\n",
      "Epoch 6/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.7966 - weighted_accuracy: 0.7260\n",
      "Epoch 00006: val_weighted_accuracy did not improve from 0.69815\n",
      "30052/30052 [==============================] - 136s 5ms/sample - loss: 0.7966 - weighted_accuracy: 0.7262 - val_loss: 0.9013 - val_weighted_accuracy: 0.6961\n",
      "Epoch 7/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.7728 - weighted_accuracy: 0.7339\n",
      "Epoch 00007: val_weighted_accuracy improved from 0.69815 to 0.69831, saving model to models/svhn.cnn.weights.best.hdf5\n",
      "30052/30052 [==============================] - 136s 5ms/sample - loss: 0.7728 - weighted_accuracy: 0.7340 - val_loss: 0.9083 - val_weighted_accuracy: 0.6983\n",
      "Epoch 8/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.7511 - weighted_accuracy: 0.7413\n",
      "Epoch 00008: val_weighted_accuracy did not improve from 0.69831\n",
      "30052/30052 [==============================] - 137s 5ms/sample - loss: 0.7511 - weighted_accuracy: 0.7411 - val_loss: 0.9173 - val_weighted_accuracy: 0.6976\n",
      "Epoch 9/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.7344 - weighted_accuracy: 0.7477\n",
      "Epoch 00009: val_weighted_accuracy did not improve from 0.69831\n",
      "30052/30052 [==============================] - 139s 5ms/sample - loss: 0.7345 - weighted_accuracy: 0.7475 - val_loss: 0.9414 - val_weighted_accuracy: 0.6970\n",
      "Epoch 10/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.7185 - weighted_accuracy: 0.7526\n",
      "Epoch 00010: val_weighted_accuracy did not improve from 0.69831\n",
      "30052/30052 [==============================] - 138s 5ms/sample - loss: 0.7185 - weighted_accuracy: 0.7526 - val_loss: 0.9412 - val_weighted_accuracy: 0.6966\n",
      "Epoch 11/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.7006 - weighted_accuracy: 0.7586\n",
      "Epoch 00011: val_weighted_accuracy did not improve from 0.69831\n",
      "30052/30052 [==============================] - 141s 5ms/sample - loss: 0.7007 - weighted_accuracy: 0.7585 - val_loss: 0.9596 - val_weighted_accuracy: 0.6956\n",
      "Epoch 12/50\n",
      "30048/30052 [============================>.] - ETA: 0s - loss: 0.6882 - weighted_accuracy: 0.7623\n",
      "Epoch 00012: val_weighted_accuracy did not improve from 0.69831\n",
      "30052/30052 [==============================] - 135s 5ms/sample - loss: 0.6884 - weighted_accuracy: 0.7622 - val_loss: 0.9674 - val_weighted_accuracy: 0.6945\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    validation_split=.1,\n",
    "                    batch_size=32,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:02.327521Z",
     "start_time": "2020-03-22T21:28:02.318940Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(history.history)\n",
    "initial_epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:04.804523Z",
     "start_time": "2020-03-22T21:28:02.330104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13066/13066 [==============================] - 52s 4ms/sample\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:04.807769Z",
     "start_time": "2020-03-22T21:28:04.805483Z"
    }
   },
   "outputs": [],
   "source": [
    "n_digits = y_pred[:, :SEQ_LENGTH]\n",
    "digits = {}\n",
    "for digit, (start, end) in digit_pos.items():\n",
    "    digits[digit] = y_pred[:, start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:04.818893Z",
     "start_time": "2020-03-22T21:28:04.809107Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274146640134701"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test[:, 0] == np.argmax(n_digits, axis=1)).sum()/len(n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:04.825578Z",
     "start_time": "2020-03-22T21:28:04.820475Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(result.history)[['val_dense_{}_acc'.format(i) for i in range(1, 7)]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:04.874179Z",
     "start_time": "2020-03-22T21:28:04.826528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1951,  519,   13,    0],\n",
       "       [ 377, 7188,  782,    9],\n",
       "       [  13,  364, 1605,   99],\n",
       "       [   0,    4,   75,   67]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test[:, 0], y_pred=np.argmax(n_digits, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:28:19.232767Z",
     "start_time": "2020-03-22T21:28:19.226923Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = np.zeros_like(y_test)\n",
    "accuracy[:, 0] = (y_test[:, 0] == np.argmax(n_digits, axis=1))\n",
    "for i in range(1, 5):\n",
    "    accuracy[:, i] = (y_test[:, i] == np.argmax(digits[i], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:29:33.680173Z",
     "start_time": "2020-03-22T21:29:33.663883Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_by_output = {}\n",
    "for i in range(5):\n",
    "    acc_by_output[i] = accuracy[:, i].sum()/accuracy[:, i].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:30:16.013528Z",
     "start_time": "2020-03-22T21:30:16.008731Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_up_to_out = {}\n",
    "for i in range(1, 6):\n",
    "    r = accuracy[:, :i].all(1)\n",
    "    acc_up_to_out[i-1] = r.sum()/r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:30:16.408957Z",
     "start_time": "2020-03-22T21:30:16.305747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'acc1': acc_by_output, 'acc2': acc_up_to_out}).plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune VGG16 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:30:21.613976Z",
     "start_time": "2020-03-22T21:30:21.600950Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "start_fine_tuning_at = 1\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in vgg16.layers[:start_fine_tuning_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:30:23.138413Z",
     "start_time": "2020-03-22T21:30:23.041127Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=weighted_entropy,\n",
    "              metrics=[weighted_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:30:25.154262Z",
     "start_time": "2020-03-22T21:30:25.152563Z"
    }
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 50\n",
    "total_epochs = initial_epochs + fine_tune_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:38:42.390321Z",
     "start_time": "2020-03-22T21:31:17.227680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30052 samples, validate on 3340 samples\n",
      "Epoch 12/62\n",
      "30052/30052 [==============================] - 426s 14ms/sample - loss: 1.2553 - weighted_accuracy: 0.5814 - val_loss: 2.3113 - val_weighted_accuracy: 0.4176\n",
      "Epoch 13/62\n",
      "30052/30052 [==============================] - 425s 14ms/sample - loss: 0.9112 - weighted_accuracy: 0.6833 - val_loss: 1.6165 - val_weighted_accuracy: 0.6145\n",
      "Epoch 14/62\n",
      "30052/30052 [==============================] - 423s 14ms/sample - loss: 0.6979 - weighted_accuracy: 0.7553 - val_loss: 1.6942 - val_weighted_accuracy: 0.6376\n",
      "Epoch 15/62\n",
      "30052/30052 [==============================] - 424s 14ms/sample - loss: 0.5504 - weighted_accuracy: 0.8132 - val_loss: 0.6740 - val_weighted_accuracy: 0.7997\n",
      "Epoch 16/62\n",
      "30052/30052 [==============================] - 426s 14ms/sample - loss: 0.4287 - weighted_accuracy: 0.8573 - val_loss: 0.5488 - val_weighted_accuracy: 0.8157\n",
      "Epoch 17/62\n",
      "30052/30052 [==============================] - 436s 15ms/sample - loss: 0.3544 - weighted_accuracy: 0.8849 - val_loss: 0.4222 - val_weighted_accuracy: 0.8683\n",
      "Epoch 18/62\n",
      "30052/30052 [==============================] - 458s 15ms/sample - loss: 0.3014 - weighted_accuracy: 0.9029 - val_loss: 0.3629 - val_weighted_accuracy: 0.8899\n",
      "Epoch 19/62\n",
      "30052/30052 [==============================] - 432s 14ms/sample - loss: 0.2676 - weighted_accuracy: 0.9146 - val_loss: 0.3564 - val_weighted_accuracy: 0.8907\n",
      "Epoch 20/62\n",
      "30052/30052 [==============================] - 423s 14ms/sample - loss: 0.2277 - weighted_accuracy: 0.9281 - val_loss: 0.3049 - val_weighted_accuracy: 0.9116\n",
      "Epoch 21/62\n",
      "30052/30052 [==============================] - 421s 14ms/sample - loss: 0.2112 - weighted_accuracy: 0.9333 - val_loss: 0.2679 - val_weighted_accuracy: 0.9241\n",
      "Epoch 22/62\n",
      "30052/30052 [==============================] - 423s 14ms/sample - loss: 0.1784 - weighted_accuracy: 0.9444 - val_loss: 0.2788 - val_weighted_accuracy: 0.9234\n",
      "Epoch 23/62\n",
      "30052/30052 [==============================] - 452s 15ms/sample - loss: 0.1606 - weighted_accuracy: 0.9500 - val_loss: 0.2634 - val_weighted_accuracy: 0.9279\n",
      "Epoch 24/62\n",
      " 9024/30052 [========>.....................] - ETA: 5:13 - loss: 0.1318 - weighted_accuracy: 0.9588WARNING:tensorflow:Early stopping conditioned on metric `val_weighted_accuracy` which is not available. Available metrics are: loss,weighted_accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-11d4929e3750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                               callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_fine_tune = model.fit(x=X_train,\n",
    "                              y=y_train,\n",
    "                              validation_split=.1,\n",
    "                              batch_size=32,\n",
    "                              epochs=total_epochs,\n",
    "                              initial_epoch=history.epoch[-1],\n",
    "                              callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:48:56.743453Z",
     "start_time": "2020-03-22T21:48:56.737527Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_tuned = metrics.append(pd.DataFrame(history_fine_tune.history), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:49:19.985635Z",
     "start_time": "2020-03-22T21:49:19.977847Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_tuned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T23:07:34.687761Z",
     "start_time": "2020-03-22T23:07:34.211805Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 4))\n",
    "metrics_tuned[['loss', 'val_loss']].plot(ax=axes[1], title='Cross-Entropy Loss')\n",
    "metrics_tuned[['weighted_accuracy', 'val_weighted_accuracy']].plot(ax=axes[0], title=f'Accuracy (Best: {metrics_tuned.val_weighted_accuracy.max():.2%})')\n",
    "axes[0].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[1].set_ylabel('Loss')\n",
    "for ax in axes:\n",
    "    ax.axvline(14, ls='--', lw=1, c='k')\n",
    "    ax.legend(['Training', 'Validation', 'Start Fine Tuning'])\n",
    "    ax.set_xlabel('Epoch')\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/transfer_learning_svhn');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
