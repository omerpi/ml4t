{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train your own word vector embeddings with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many tasks require embeddings or domain-specific vocabulary that pre-trained models based on a generic corpus may not represent well or at all. Standard word2vec models are not able to assign vectors to out-of-vocabulary words and instead use a default vector that reduces their predictive value.\n",
    "\n",
    "E.g., when working with industry-specific documents, the vocabulary or its usage may change over time as new technologies or products emerge. As a result, the embeddings need to evolve as well. In addition, corporate earnings releases use nuanced language not fully reflected in Glove vectors pre-trained on Wikipedia articles.\n",
    "\n",
    "We will illustrate the word2vec architecture using the keras library that we will introduce in more detail in the next chapter and the more performant gensim adaptation of the code provided by the word2vec authors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the word2vec network architecture, we use the Financial News data that we first introduced in chapter 14 on Topic Modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not yet install `TensorFlow 2`, uncomment and run one of the following, the first if you have a GPU and the second otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -n ml4t-text tensorflow-gpu -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -n ml4t-text tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.671340Z",
     "start_time": "2020-03-12T18:45:29.464584Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Dot, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams, make_sampling_table\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.675046Z",
     "start_time": "2020-03-12T18:45:30.672377Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "pd.set_option('float_format', '{:,.2f}'.format)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T02:11:55.353290Z",
     "start_time": "2020-03-13T02:11:55.350325Z"
    }
   },
   "outputs": [],
   "source": [
    "news_path = Path('data', 'fin_news')\n",
    "data_path = news_path / 'data'\n",
    "analogy_path = Path('data', 'analogies', 'analogies-en.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.697140Z",
     "start_time": "2020-03-12T18:45:30.690530Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f'{h:02.0f}:{m:02.0f}:{s:02.0f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `word2vec` - skipgram Architecture using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.704883Z",
     "start_time": "2020-03-12T18:45:30.698088Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LANGUAGE = 'en'\n",
    "SAMPLE_SIZE=.5              # portion of sentences to use for model\n",
    "NGRAMS = 3                  # Longest ngram in text\n",
    "MIN_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.713223Z",
     "start_time": "2020-03-12T18:45:30.705703Z"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLING_FACTOR = 1e-4\n",
    "WINDOW_SIZE = 3\n",
    "EMBEDDING_SIZE = 300\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.721393Z",
     "start_time": "2020-03-12T18:45:30.714065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up validation\n",
    "VALID_SET = 10      # Random set of words to get nearest neighbors for\n",
    "VALID_WINDOW = 150  # Most frequent words to draw validation set from\n",
    "NN = 10             # Number of nearest neighbors for evaluation\n",
    "\n",
    "valid_examples = np.random.choice(VALID_WINDOW, size=VALID_SET, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.729167Z",
     "start_time": "2020-03-12T18:45:30.722876Z"
    }
   },
   "outputs": [],
   "source": [
    "FILE_NAME = f'articles_{NGRAMS}_grams.txt'\n",
    "file_path = data_path / FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:30.744368Z",
     "start_time": "2020-03-12T18:45:30.730171Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tb_path = news_path / 'tensorboard'\n",
    "if not tb_path.exists():\n",
    "    tb_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Tokens to ID\n",
    "\n",
    "1. Extract the top *n* most common words to learn embeddings\n",
    "2. Index these *n* words with unique integers\n",
    "3. Create an `{index: word}` dictionary\n",
    "4. Replace the *n* words with their index, and a dummy value `UNK` elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:39.807598Z",
     "start_time": "2020-03-12T18:45:30.745336Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = file_path.read_text().split('\\n')\n",
    "words = ' '.join(np.random.choice(sentences, size=int(.5*len(sentences)), replace=False)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:44.141863Z",
     "start_time": "2020-03-12T18:45:39.808428Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get (token, count) tuples for tokens meeting MIN_FREQ \n",
    "token_counts = [t for t in Counter(words).most_common() if t[1] >= MIN_FREQ]\n",
    "tokens, counts = list(zip(*token_counts))\n",
    "\n",
    "# create id-token dicts & reverse dicts\n",
    "id_to_token = pd.Series(tokens, index=range(1, len(tokens) + 1)).to_dict()\n",
    "id_to_token.update({0: 'UNK'})\n",
    "token_to_id = {t:i for i, t in id_to_token.items()}\n",
    "data = [token_to_id.get(word, 0) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:44.144427Z",
     "start_time": "2020-03-12T18:45:44.142781Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:44.164654Z",
     "start_time": "2020-03-12T18:45:44.145306Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:47.292795Z",
     "start_time": "2020-03-12T18:45:44.165475Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(data).value_counts().reset_index()\n",
    "s.columns = ['id', 'count']\n",
    "s['token'] = s.id.map(id_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:47.305427Z",
     "start_time": "2020-03-12T18:45:47.293726Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>count</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>411047</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>171157</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>168115</td>\n",
       "      <td>million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>144088</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>110774</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>106468</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>82508</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>78595</td>\n",
       "      <td>reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>73047</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>72307</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   count      token\n",
       "0   0  411047        UNK\n",
       "1   1  171157    company\n",
       "2   2  168115    million\n",
       "3   3  144088       said\n",
       "4   4  110774       year\n",
       "5   5  106468    quarter\n",
       "6   6   82508  financial\n",
       "7   7   78595    reuters\n",
       "8   8   73047        net\n",
       "9   9   72307        new"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sort_values('count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:47.311671Z",
     "start_time": "2020-03-12T18:45:47.306487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17391040"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:47.385659Z",
     "start_time": "2020-03-12T18:45:47.312594Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.sort_values('id').token.dropna().to_csv(tb_path / 'meta.tsv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Analogies to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:47.447288Z",
     "start_time": "2020-03-12T18:45:47.386565Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_analogies():\n",
    "    df = pd.read_csv(analogy_path, header=None, squeeze=True)\n",
    "    categories = df[df.str.startswith(':')]\n",
    "    analogies = df[~df.str.startswith(':')].str.split(expand=True)\n",
    "    analogies.columns = list('abcd')\n",
    "    return analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:47.453906Z",
     "start_time": "2020-03-12T18:45:47.448245Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>athens</td>\n",
       "      <td>greece</td>\n",
       "      <td>baghdad</td>\n",
       "      <td>iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>athens</td>\n",
       "      <td>greece</td>\n",
       "      <td>bangkok</td>\n",
       "      <td>thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>athens</td>\n",
       "      <td>greece</td>\n",
       "      <td>beijing</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>athens</td>\n",
       "      <td>greece</td>\n",
       "      <td>berlin</td>\n",
       "      <td>germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>athens</td>\n",
       "      <td>greece</td>\n",
       "      <td>bern</td>\n",
       "      <td>switzerland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a       b        c            d\n",
       "1  athens  greece  baghdad         iraq\n",
       "2  athens  greece  bangkok     thailand\n",
       "3  athens  greece  beijing        china\n",
       "4  athens  greece   berlin      germany\n",
       "5  athens  greece     bern  switzerland"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogies = get_analogies()\n",
    "analogies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:49.280232Z",
     "start_time": "2020-03-12T18:45:47.454770Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7269218651543793"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogies_id = analogies.apply(lambda x: x.map(token_to_id))\n",
    "analogies_id.notnull().all(1).sum()/len(analogies_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate Sampling Probabilities\n",
    "\n",
    "There is an alternative, faster scheme than the traditional SoftMax loss function called [Noise Contrastive Estimation (NCE)](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf).\n",
    "\n",
    "Instead of getting the softmax probability for all possible context words, randomly sample 2-20 possible context words and evaluate the probability only for these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**SAMPLING_FACTOR**: used for generating the `sampling_table` argument for `skipgrams`. \n",
    "\n",
    "`sampling_table[i]` is the probability of sampling the word i-th most common word in a dataset\n",
    "\n",
    "The sampling probabilities are generated according\n",
    "to the sampling distribution used in word2vec:\n",
    "\n",
    "$p(\\text{word}) = \\min\\left(1, \\frac{\\sqrt{\\frac{\\text{word frequency}}{\\text{sampling factor}}}}{\\frac{\\text{word frequency}}{\\text{sampling factor}}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:49.929549Z",
     "start_time": "2020-03-12T18:45:49.281227Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = s['count'].to_frame('freq')\n",
    "factors = [1, 1e-2, 1e-4, 1e-6, 1e-8]\n",
    "for f in factors:\n",
    "    sf = make_sampling_table(vocab_size, sampling_factor=f)\n",
    "    df[f] = df.freq.mul(sf)\n",
    "df.loc[:, factors].plot(logy=True, xlim=(0, 60000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:49.933764Z",
     "start_time": "2020-03-12T18:45:49.930592Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sampling_table = make_sampling_table(vocab_size, sampling_factor=SAMPLING_FACTOR/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:45:50.170656Z",
     "start_time": "2020-03-12T18:45:49.935610Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(sampling_table).plot(title='Skip-Gram Sampling Probabilities')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate target-context word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:48:31.789063Z",
     "start_time": "2020-03-12T18:45:50.171986Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pairs, labels = skipgrams(sequence=data,\n",
    "                          vocabulary_size=vocab_size,\n",
    "                          window_size=WINDOW_SIZE,\n",
    "                          sampling_table=sampling_table,\n",
    "                          negative_samples=1.0,\n",
    "                          shuffle=True)\n",
    "\n",
    "print('{:,d} pairs created'.format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:22.666286Z",
     "start_time": "2020-03-12T18:48:31.790082Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "target_word, context_word = np.array(pairs, dtype=np.int32).T\n",
    "labels = np.array(labels, dtype=np.int8)\n",
    "del pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:22.670162Z",
     "start_time": "2020-03-12T18:50:22.667361Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "target_word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:22.703543Z",
     "start_time": "2020-03-12T18:50:22.671578Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'target': target_word[:5], \n",
    "                   'context': context_word[:5], \n",
    "                   'label': labels[:5]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:23.121027Z",
     "start_time": "2020-03-12T18:50:22.704358Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.090488Z",
     "start_time": "2020-03-12T18:50:23.121917Z"
    },
    "hide_input": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(news_path / 'data.h5') as store:\n",
    "    store.put('id_to_token', pd.Series(id_to_token))\n",
    "    store.put('pairs', pd.DataFrame({'target' : target_word,\n",
    "                                     'context': context_word, \n",
    "                                     'labels': labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(news_path / 'data.h5') as store:\n",
    "    id_to_token = store['id_to_token']\n",
    "    pairs = store['pairs']\n",
    "target_word, context_word, labels = pairs.target, pairs.context, pairs.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define Keras Model Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Scalar Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.096041Z",
     "start_time": "2020-03-12T18:50:24.091336Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "input_target = Input((1,), name='target_input')\n",
    "input_context = Input((1,), name='context_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Shared Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.102819Z",
     "start_time": "2020-03-12T18:50:24.097380Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embedding = Embedding(input_dim=vocab_size,\n",
    "                      output_dim=EMBEDDING_SIZE,\n",
    "                      input_length=1,\n",
    "                      name='embedding_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.298600Z",
     "start_time": "2020-03-12T18:50:24.103786Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "target = embedding(input_target)\n",
    "target = Reshape((EMBEDDING_SIZE, 1), name='target_embedding')(target)\n",
    "\n",
    "context = embedding(input_context)\n",
    "context = Reshape((EMBEDDING_SIZE, 1), name='context_embedding')(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.311253Z",
     "start_time": "2020-03-12T18:50:24.299949Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dot_product = Dot(axes=1)([target, context])\n",
    "dot_product = Reshape((1,), name='similarity')(dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sigmoid Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.842906Z",
     "start_time": "2020-03-12T18:50:24.312127Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "output = Dense(units=1, activation='sigmoid', name='output')(dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Compile Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.861976Z",
     "start_time": "2020-03-12T18:50:24.843762Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_target, input_context], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.866315Z",
     "start_time": "2020-03-12T18:50:24.862839Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "target_input (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context_input (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     (None, 1, 300)       17885100    target_input[0][0]               \n",
      "                                                                 context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Reshape)      (None, 300, 1)       0           embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Reshape)     (None, 300, 1)       0           embedding_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           target_embedding[0][0]           \n",
      "                                                                 context_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "similarity (Reshape)            (None, 1)            0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           similarity[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 17,885,102\n",
      "Trainable params: 17,885,102\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Validation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.881662Z",
     "start_time": "2020-03-12T18:50:24.867314Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "similarity = Dot(normalize=True, \n",
    "                 axes=1, \n",
    "                 name='cosine_similarity')([target, context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.885940Z",
     "start_time": "2020-03-12T18:50:24.882733Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a secondary validation model to run our similarity checks during training\n",
    "validation_model = Model(inputs=[input_target, input_context], outputs=similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.900861Z",
     "start_time": "2020-03-12T18:50:24.886959Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "target_input (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context_input (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     (None, 1, 300)       17885100    target_input[0][0]               \n",
      "                                                                 context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Reshape)      (None, 300, 1)       0           embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Reshape)     (None, 300, 1)       0           embedding_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cosine_similarity (Dot)         (None, 1, 1)         0           target_embedding[0][0]           \n",
      "                                                                 context_embedding[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 17,885,100\n",
      "Trainable params: 17,885,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "validation_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Keras Graph](https://s3.amazonaws.com/applied-ai/images/keras_graph_tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create Keras Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "####  Nearest Neighors & Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.911288Z",
     "start_time": "2020-03-12T18:50:24.901953Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_set = analogies_id.dropna().astype(int)\n",
    "a, b, c, actual = test_set.values.T\n",
    "actual = actual.reshape(-1, 1)\n",
    "n_analogies = len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.919709Z",
     "start_time": "2020-03-12T18:50:24.912303Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class EvalCallback(Callback):\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.eval_nn()\n",
    "        self.test_analogies()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.eval_nn()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.test_analogies()\n",
    "\n",
    "    @staticmethod\n",
    "    def test_analogies():\n",
    "        print('\\nAnalogy Accuracy:\\n\\t', end='')\n",
    "        embeddings = embedding.get_weights()[0]\n",
    "        target = embeddings[c] + embeddings[b] - embeddings[a]\n",
    "        neighbors = np.argsort(cdist(target, embeddings, metric='cosine'))\n",
    "        match_id = np.argwhere(neighbors == actual)[:, 1]\n",
    "        print('\\n\\t'.join(['Top {}: {:.2%}'.format(i, (match_id < i).sum() / n_analogies) for i in [1, 5, 10]]))\n",
    "\n",
    "    def eval_nn(self):\n",
    "        print('\\n{} Nearest Neighbors:'.format(NN))\n",
    "        for i in range(VALID_SET):\n",
    "            valid_id = valid_examples[i]\n",
    "            valid_word = id_to_token[valid_id]\n",
    "            similarity = self._get_similiarity(valid_id).reshape(-1)\n",
    "            nearest = (-similarity).argsort()[1:NN + 1]\n",
    "            neighbors = [id_to_token[nearest[n]] for n in range(NN)]\n",
    "            print('{}:\\t{}'.format(valid_word, ', '.join(neighbors)))            \n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_similiarity(valid_word_idx):\n",
    "        target = np.full(shape=vocab_size, fill_value=valid_word_idx)\n",
    "        context = np.arange(vocab_size)\n",
    "        return validation_model.predict([target, context])\n",
    "\n",
    "\n",
    "evaluation = EvalCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Tensorboard Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently tensorflow has a [bug](https://github.com/tensorflow/tensorflow/issues/32902) that prevents metadata from working. The GitHub issue points to a simple fix that you can apply to the tensorflow source code, just search for the culprit line and change accordingly until a later release remedies this problem. You will have to install with `pip` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T18:50:24.927930Z",
     "start_time": "2020-03-12T18:50:24.920991Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=str(tb_path),\n",
    "                          write_graph=True,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_metadata={'embedding_layer': \n",
    "                                               str(tb_path / 'meta.tsv')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T20:36:06.967560Z",
     "start_time": "2020-03-12T18:50:24.929601Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 Nearest Neighbors:\n",
      "loss:\tgernot_heller, san_ramon, stamos, three_fold, facilitate, cheating, well_timed, relocations, imperialism, philipp\n",
      "non:\trobin, aoun, michael_froman, leaves_downing_street, falzone, sirius_xm_holdings, vivek_mishra, taxman, estimation_mineral_reserves, cornerstone\n",
      "service:\ttahoe, fraport, aligns, saleable_equivalent, celldex_therapeutics, belgravia, actuarial_gains_losses, deficit, predictability, endo_bariatric\n",
      "announced:\tvitalhub, plutonic_gold, controllers, reproductive_medicine, life_threatening_diseases, mellanox, mexus, purging, doug_mcmillon, lynne\n",
      "ebitda:\tclarifying, leftist_front_runner_andres, trimming, committee_medicinal, reflecting, sarajevo, momentous, bot, assurant, alien\n",
      "december:\tfiancee_meghan_markle, spare_parts, bgc, gina_cherelus, pki, peruvian, luciano_costa, fabre, flynn, nioc\n",
      "securities:\tpandora_box, scholl, crippling, human_trafficking, fy_fy, jostle, slope, replacements, babcock_wilcox_enterprises, writing_maria_kiselyova\n",
      "result:\tvegetation, kia_motors, czaputowicz, greylock, voiced_concerns, teal, newlink_genetics, karnataka, ice_hockey_team, zijlstra\n",
      "months:\tneuro_spinal_scaffold, synthego, gradient, cpas, crypto, vistaprint, collaborated, anti_establishment_movement, cautionary_note, fridays\n",
      "available:\tmanagement, chi, attend, fraser, renovation, suchitra_mohanty, bloomberg, jason_neely, brightness, comparable_similarly\n",
      "\n",
      "Analogy Accuracy:\n",
      "\tTop 1: 0.00%\n",
      "\tTop 5: 0.02%\n",
      "\tTop 10: 0.03%\n",
      "24942/24942 [==============================] - ETA: 0s - loss: 0.5086\n",
      "Analogy Accuracy:\n",
      "\tTop 1: 0.01%\n",
      "\tTop 5: 1.85%\n",
      "\tTop 10: 2.39%\n",
      "24942/24942 [==============================] - 3048s 122ms/step - loss: 0.5086\n",
      "\n",
      "10 Nearest Neighbors:\n",
      "loss:\tlosses, ffo, earnings, gains_losses, revenues, cate_cadell_beijing, rushil_dutta, croat, piper_jaffray_attention_prospectus, divine\n",
      "non:\ttotal, did, end, december, medical, banks, adjusted, key, this, making\n",
      "service:\tsegment, however, going, networks, it, hops, wrist, modernity, bell_creek, baader\n",
      "announced:\tmanaging_director, announces, pleased_announce, joins, comes, brings, worked, getty_images, delivers, led\n",
      "ebitda:\tamounts, ffo, sharay_angulo, izumi_nakagawa, revenues, writing_fergus_jensen, cate_cadell_beijing, ankur_banerjee, recurrent_glioblastoma, writing_sofia_christensen\n",
      "december:\tfebruary, november, march, power, fourth, april, june, january, segment, like\n",
      "securities:\tnotes, power, communication, sale, segment, legal, having, bonds, on, college\n",
      "result:\tresulting, resulted, associated, driven, required, saw, connection, harvard_trained_economist, needed, face\n",
      "months:\tweeks, fifty_two_weeks, days, spurious, writing_bruno_federowski, academically, pig_iron, ellen_francis_beirut, proclaiming, hinds_bock\n",
      "available:\taccessed, face, added, says, received, open, access, reached, like, did\n"
     ]
    }
   ],
   "source": [
    "loss = model.fit(x=[target_word, context_word],\n",
    "                 y=labels,\n",
    "                 shuffle=True,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 epochs=EPOCHS,\n",
    "                 callbacks=[evaluation, tensorboard] # uncomment if tensorboard bug is fixed\n",
    "#                  callbacks=[evaluation]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:07:04.418012Z",
     "start_time": "2020-03-12T22:07:04.252405Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(str(news_path / 'keras' / 'skipgram_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Embeddings using Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings metadata using the `load` option to view embedding labels and see [tutorial](https://www.tensorflow.org/tensorboard/get_started) for usage instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T02:13:04.218276Z",
     "start_time": "2020-03-13T02:13:04.215012Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T02:13:07.141463Z",
     "start_time": "2020-03-13T02:13:04.979550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3e31d396ca9c983c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3e31d396ca9c983c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir data/fin_news/tensorboard/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Distributed representations of words and phrases and their compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "- [Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf?)\n",
    "- [Sebastian Ruder's Blog](http://ruder.io/word-embeddings-1/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47px",
    "left": "38px",
    "right": "1340px",
    "top": "66.5px",
    "width": "362px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
