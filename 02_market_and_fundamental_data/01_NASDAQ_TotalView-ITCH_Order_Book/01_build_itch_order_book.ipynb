{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:04:35.998101Z",
     "start_time": "2018-12-25T19:04:35.989183Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from struct import unpack\n",
    "from collections import namedtuple, Counter\n",
    "from datetime import timedelta\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NASDAQ ITCH Data from FTP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:16:28.970811Z",
     "start_time": "2018-12-25T17:16:28.966866Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('data') # set to e.g. external harddrive\n",
    "itch_store = str(data_path / 'itch.h5')\n",
    "order_book_store = data_path / 'order_book.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:16:30.190820Z",
     "start_time": "2018-12-25T17:16:30.189063Z"
    }
   },
   "outputs": [],
   "source": [
    "FTP_URL = 'ftp://emi.nasdaq.com/ITCH/'\n",
    "SOURCE_FILE = '03292018.NASDAQ_ITCH50.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:17:03.453672Z",
     "start_time": "2018-12-25T17:17:03.444627Z"
    }
   },
   "outputs": [],
   "source": [
    "def may_be_download(url):\n",
    "    \"\"\"Download & unzip ITCH data if not yet available\"\"\"\n",
    "    filename = data_path/ url.split('/')[-1]\n",
    "    if not data_path.exists():\n",
    "        data_path.mkdir()\n",
    "    if not filename.exists():\n",
    "        urlretrieve(url, filename)\n",
    "    unzipped = data_path / (filename.stem + '.bin')\n",
    "    if not (data_path / unzipped).exists():\n",
    "        with gzip.open(str(filename), 'rb') as f_in:\n",
    "            with open(unzipped, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    return unzipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will download 4GB data that unzips to 9.4GB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:06:08.577453Z",
     "start_time": "2018-12-25T19:06:08.570117Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = may_be_download(FTP_URL + SOURCE_FILE)\n",
    "date = file_name.name.split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITCH Format Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.630040Z",
     "start_time": "2018-12-25T17:23:09.628023Z"
    }
   },
   "outputs": [],
   "source": [
    "event_codes = {'O': 'Start of Messages',\n",
    "               'S': 'Start of System Hours',\n",
    "               'Q': 'Start of Market Hours',\n",
    "               'M': 'End of Market Hours',\n",
    "               'E': 'End of System Hours',\n",
    "               'C': 'End of Messages'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.841397Z",
     "start_time": "2018-12-25T17:23:09.835447Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = {'primary_market_maker': {'Y': 1, 'N': 0},\n",
    "            'printable'           : {'Y': 1, 'N': 0},\n",
    "            'buy_sell_indicator'  : {'B': 1, 'S': -1},\n",
    "            'cross_type'          : {'O': 0, 'C': 1, 'H': 2},\n",
    "            'imbalance_direction' : {'B': 0, 'S': 1, 'N': 0, 'O': -1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:23:09.999064Z",
     "start_time": "2018-12-25T17:23:09.992338Z"
    }
   },
   "outputs": [],
   "source": [
    "formats = {\n",
    "    ('integer', 2): 'H',\n",
    "    ('integer', 4): 'I',\n",
    "    ('integer', 6): '6s',\n",
    "    ('integer', 8): 'Q',\n",
    "    ('alpha', 1)  : 's',\n",
    "    ('alpha', 2)  : '2s',\n",
    "    ('alpha', 4)  : '4s',\n",
    "    ('alpha', 8)  : '8s',\n",
    "    ('price_4', 4): 'I',\n",
    "    ('price_8', 8): 'Q',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create message specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:12:03.563469Z",
     "start_time": "2018-12-25T18:12:03.559160Z"
    }
   },
   "outputs": [],
   "source": [
    "specs_path = Path('message_specs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:18.635039Z",
     "start_time": "2018-12-25T18:36:18.630282Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_message_types(df):\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "    df.value = df.value.str.strip()\n",
    "    df.name = (df.name\n",
    "               .str.strip()\n",
    "               .str.lower()\n",
    "               .str.replace(' ', '_')\n",
    "               .str.replace('-', '_')\n",
    "               .str.replace('/', '_'))\n",
    "    df.notes = df.notes.str.strip()\n",
    "    df['message_type'] = df.loc[df.name == 'message_type', 'value']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Message Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:19.798092Z",
     "start_time": "2018-12-25T18:36:19.783135Z"
    }
   },
   "outputs": [],
   "source": [
    "message_types = clean_message_types(pd.read_excel('message_types.xlsx',\n",
    "                                                  sheet_name='messages',\n",
    "                                                  encoding='latin1')\n",
    "                                    .sort_values('id')\n",
    "                                    .drop('id', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Message Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:22.741964Z",
     "start_time": "2018-12-25T18:36:22.734576Z"
    }
   },
   "outputs": [],
   "source": [
    "message_labels = (df.loc[:, ['message_type', 'notes']]\n",
    "                  .dropna()\n",
    "                  .rename(columns={'notes': 'name'}))\n",
    "message_labels.name = (message_labels.name\n",
    "                       .str.lower()\n",
    "                       .str.replace('message', '')\n",
    "                       .str.replace('.', '')\n",
    "                       .str.strip().str.replace(' ', '_'))\n",
    "# message_labels.to_csv('message_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:36:57.493706Z",
     "start_time": "2018-12-25T18:36:56.614416Z"
    }
   },
   "outputs": [],
   "source": [
    "message_types.message_type = message_types.message_type.ffill()\n",
    "message_types = message_types[message_types.name != 'message_type']\n",
    "message_types.value = (message_types.value\n",
    "                       .str.lower()\n",
    "                       .str.replace(' ', '_')\n",
    "                       .str.replace('(', '')\n",
    "                       .str.replace(')', ''))\n",
    "message_types.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get message specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:28:19.337714Z",
     "start_time": "2018-12-25T17:28:19.230013Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i 'create_message_spec.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:25.322056Z",
     "start_time": "2018-12-25T17:29:25.291911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get ITCH specs and create formatting (type, length) tuples\n",
    "specs = pd.read_csv('message_types.csv')\n",
    "specs['formats'] = specs[['value', 'length']].apply(tuple, axis=1).map(formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:27.058965Z",
     "start_time": "2018-12-25T17:29:27.044699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract formatting for alphanumerical fields\n",
    "alpha_fields = specs[specs.value == 'alpha'].set_index('name')\n",
    "alpha_msgs = alpha_fields.groupby('message_type')\n",
    "alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}\n",
    "alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:27.755034Z",
     "start_time": "2018-12-25T17:29:27.722828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate message classes as named tuples and format strings\n",
    "message_fields, fstring = {}, {}\n",
    "for t, message in specs.groupby('message_type'):\n",
    "    message_fields[t] = namedtuple(typename=t, field_names=message.name.tolist())\n",
    "    fstring[t] = '>' + ''.join(message.formats.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:28.145192Z",
     "start_time": "2018-12-25T17:29:28.131796Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_alpha(mtype, data):\n",
    "    \"\"\"Process byte strings of type alpha\"\"\"\n",
    "\n",
    "    for col in alpha_formats.get(mtype).keys():\n",
    "        if mtype != 'R' and col == 'stock':\n",
    "            data = data.drop(col, axis=1)\n",
    "            continue\n",
    "        data.loc[:, col] = data.loc[:, col].str.decode(\"utf-8\").str.strip()\n",
    "        if encoding.get(col):\n",
    "            data.loc[:, col] = data.loc[:, col].map(encoding.get(col))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:45.620911Z",
     "start_time": "2018-12-25T17:29:45.606916Z"
    }
   },
   "outputs": [],
   "source": [
    "def store_messages(m):\n",
    "    \"\"\"Handle occasional storing of all messages\"\"\"\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        for mtype, data in m.items():\n",
    "            # convert to DataFrame\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "            # parse timestamp info\n",
    "            data.timestamp = data.timestamp.apply(int.from_bytes, byteorder='big')\n",
    "            data.timestamp = pd.to_timedelta(data.timestamp)\n",
    "\n",
    "            # apply alpha formatting\n",
    "            if mtype in alpha_formats.keys():\n",
    "                data = format_alpha(mtype, data)\n",
    "\n",
    "            s = alpha_length.get(mtype)\n",
    "            if s:\n",
    "                s = {c: s.get(c) for c in data.columns}\n",
    "            dc = ['stock_locate']\n",
    "            if m == 'R':\n",
    "                dc.append('stock')\n",
    "            store.append(mtype,\n",
    "                         data,\n",
    "                         format='t',\n",
    "                         min_itemsize=s,\n",
    "                         data_columns=dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:29:45.638871Z",
     "start_time": "2018-12-25T17:29:45.623938Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = {}\n",
    "message_count = 0\n",
    "message_type_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T17:59:34.870288Z",
     "start_time": "2018-12-25T17:29:45.640518Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with (data_path / file_name).open('rb') as data:\n",
    "    while True:\n",
    "        \n",
    "        # determine message size in bytes\n",
    "        message_size = int.from_bytes(data.read(2), byteorder='big', signed=False)\n",
    "        \n",
    "        # get message type by reading first byte\n",
    "        message_type = data.read(1).decode('ascii')\n",
    "        \n",
    "        # create data structure to capture result\n",
    "        if not messages.get(message_type):\n",
    "            messages[message_type] = []\n",
    "\n",
    "        message_type_counter.update([message_type])\n",
    "\n",
    "        # read & store message\n",
    "        record = data.read(message_size - 1)\n",
    "        message = message_fields[message_type]._make(unpack(fstring[message_type], record))\n",
    "        messages[message_type].append(message)\n",
    "        \n",
    "        # deal with system events\n",
    "        if message_type == 'S':\n",
    "            timestamp = int.from_bytes(message.timestamp, byteorder='big')\n",
    "            print('\\n', event_codes.get(message.event_code.decode('ascii'), 'Error'))\n",
    "            print('\\t{0}\\t{1:,.0f}'.format(timedelta(seconds=timestamp * 1e-9),\n",
    "                                         message_count))\n",
    "            if message.event_code.decode('ascii') == 'C':\n",
    "                store_messages(messages)\n",
    "                break\n",
    "\n",
    "        message_count += 1\n",
    "        if message_count % 2.5e7 == 0:\n",
    "            timestamp = int.from_bytes(message.timestamp, byteorder='big')\n",
    "            print('\\t{0}\\t{1:,.0f}\\t{2}'.format(timedelta(seconds=timestamp * 1e-9),\n",
    "                                                message_count,\n",
    "                                                timedelta(seconds=time() - start)))\n",
    "            store_messages(messages)\n",
    "            messages = {}\n",
    "            \n",
    "        \n",
    "print(timedelta(seconds=time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Trading Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Message Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:03.560168Z",
     "start_time": "2018-12-25T18:38:03.551636Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = pd.Series(message_type_counter).to_frame('# Trades')\n",
    "counter['Message Type'] = counter.index.map(message_labels.set_index('message_type').name.to_dict())\n",
    "counter = counter[['Message Type', '# Trades']].sort_values('# Trades', ascending=False)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:05.819908Z",
     "start_time": "2018-12-25T18:38:05.810713Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    store.put('summary', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Equities by Traded Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:22.781356Z",
     "start_time": "2018-12-25T18:38:21.989429Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(itch_store) as store:\n",
    "    stocks = store['R'].loc[:, ['stock_locate', 'stock']]\n",
    "    trades = store['P'].append(store['Q'].rename(columns={'cross_price': 'price'}), sort=False).merge(stocks)\n",
    "trades['value'] = trades.shares.mul(trades.price)\n",
    "trades['value_share'] = trades.value.div(trades.value.sum())\n",
    "trade_summary = trades.groupby('stock').value_share.sum().sort_values(ascending=False)\n",
    "trade_summary.iloc[:50].plot.bar(figsize=(14, 6), color='darkblue', title='Share of Traded Value')\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Order Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:22.784560Z",
     "start_time": "2018-12-25T18:38:22.782597Z"
    }
   },
   "outputs": [],
   "source": [
    "stock = 'AAPL'\n",
    "order_dict = {-1: 'sell', 1: 'buy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all messages for given stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:22.794673Z",
     "start_time": "2018-12-25T18:38:22.785605Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_messages(date, stock=stock):\n",
    "    \"\"\"Collect trading messages for given stock\"\"\"\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        stock_locate = store.select('R', where='stock = stock').stock_locate.iloc[0]\n",
    "        target = 'stock_locate = stock_locate'\n",
    "\n",
    "        data = {}\n",
    "        # trading message types\n",
    "        messages = ['A', 'F', 'E', 'C', 'X', 'D', 'U', 'P', 'Q']\n",
    "        for m in messages:\n",
    "            data[m] = store.select(m, where=target).drop('stock_locate', axis=1).assign(type=m)\n",
    "\n",
    "    order_cols = ['order_reference_number', 'buy_sell_indicator', 'shares', 'price']\n",
    "    orders = pd.concat([data['A'], data['F']], sort=False, ignore_index=True).loc[:, order_cols]\n",
    "\n",
    "    for m in messages[2: -3]:\n",
    "        data[m] = data[m].merge(orders, how='left')\n",
    "\n",
    "    data['U'] = data['U'].merge(orders, how='left',\n",
    "                                right_on='order_reference_number',\n",
    "                                left_on='original_order_reference_number',\n",
    "                                suffixes=['', '_replaced'])\n",
    "\n",
    "    data['Q'].rename(columns={'cross_price': 'price'}, inplace=True)\n",
    "    data['X']['shares'] = data['X']['cancelled_shares']\n",
    "    data['X'] = data['X'].dropna(subset=['price'])\n",
    "\n",
    "    data = pd.concat([data[m] for m in messages], ignore_index=True, sort=False)\n",
    "    data['date'] = pd.to_datetime(date, format='%m%d%Y')\n",
    "    data.timestamp = data['date'].add(data.timestamp)\n",
    "    data = data[data.printable != 0]\n",
    "\n",
    "    drop_cols = ['tracking_number', 'order_reference_number', 'original_order_reference_number',\n",
    "                 'cross_type', 'new_order_reference_number', 'attribution', 'match_number',\n",
    "                 'printable', 'date', 'cancelled_shares']\n",
    "    return data.drop(drop_cols, axis=1).sort_values('timestamp').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.320030Z",
     "start_time": "2018-12-25T18:38:22.796992Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = get_messages(date=date)\n",
    "messages.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.453686Z",
     "start_time": "2018-12-25T18:38:31.322040Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    key = '{}/messages'.format(stock)\n",
    "    store.put(key, messages)\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Trading Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.458668Z",
     "start_time": "2018-12-25T18:38:31.455129Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trades(m):\n",
    "    \"\"\"Combine C, E, P and Q messages into trading records\"\"\"\n",
    "    trade_dict = {'executed_shares': 'shares', 'execution_price': 'price'}\n",
    "    cols = ['timestamp', 'executed_shares']\n",
    "    trades = pd.concat([m.loc[m.type == 'E', cols + ['price']].rename(columns=trade_dict),\n",
    "                        m.loc[m.type == 'C', cols + ['execution_price']].rename(columns=trade_dict),\n",
    "                        m.loc[m.type == 'P', ['timestamp', 'price', 'shares']],\n",
    "                        m.loc[m.type == 'Q', ['timestamp', 'price', 'shares']].assign(cross=1),\n",
    "                        ], sort=False).dropna(subset=['price']).fillna(0)\n",
    "    return trades.set_index('timestamp').sort_index().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.707339Z",
     "start_time": "2018-12-25T18:38:31.459640Z"
    }
   },
   "outputs": [],
   "source": [
    "trades = get_trades(messages)\n",
    "print(trades.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.716334Z",
     "start_time": "2018-12-25T18:38:31.708217Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    store.put('{}/trades'.format(stock), trades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.727288Z",
     "start_time": "2018-12-25T18:38:31.717324Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_orders(orders, buysell, nlevels):\n",
    "    \"\"\"Add orders up to desired depth given by nlevels;\n",
    "        sell in ascending, buy in descending order\n",
    "    \"\"\"\n",
    "    new_order = []\n",
    "    items = sorted(orders.copy().items())\n",
    "    if buysell == 1:\n",
    "        items = reversed(items)  \n",
    "    for i, (p, s) in enumerate(items, 1):\n",
    "        new_order.append((p, s))\n",
    "        if i == nlevels:\n",
    "            break\n",
    "    return orders, new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:38:31.738494Z",
     "start_time": "2018-12-25T18:38:31.728222Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_orders(orders, append=False):\n",
    "    cols = ['price', 'shares']\n",
    "    for buysell, book in orders.items():\n",
    "        df = (pd.concat([pd.DataFrame(data=data,\n",
    "                                     columns=cols)\n",
    "                         .assign(timestamp=t) \n",
    "                         for t, data in book.items()]))\n",
    "        key = '{}/{}'.format(stock, order_dict[buysell])\n",
    "        df.loc[:, ['price', 'shares']] = df.loc[:, ['price', 'shares']].astype(int)\n",
    "        with pd.HDFStore(order_book_store) as store:\n",
    "            if append:\n",
    "                store.append(key, df.set_index('timestamp'), format='t')\n",
    "            else:\n",
    "                store.put(key, df.set_index('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:13.364384Z",
     "start_time": "2018-12-25T18:38:31.739374Z"
    }
   },
   "outputs": [],
   "source": [
    "order_book = {-1: {}, 1: {}}\n",
    "current_orders = {-1: Counter(), 1: Counter()}\n",
    "message_counter = Counter()\n",
    "nlevels = 100\n",
    "\n",
    "start = time()\n",
    "for message in messages.itertuples():\n",
    "    i = message[0]\n",
    "    if i % 1e5 == 0 and i > 0:\n",
    "        print('{:,.0f}\\t\\t{}'.format(i, timedelta(seconds=time() - start)))\n",
    "        save_orders(order_book, append=True)\n",
    "        order_book = {-1: {}, 1: {}}\n",
    "        start = time()\n",
    "    if np.isnan(message.buy_sell_indicator):\n",
    "        continue\n",
    "    message_counter.update(message.type)\n",
    "\n",
    "    buysell = message.buy_sell_indicator\n",
    "    price, shares = None, None\n",
    "\n",
    "    if message.type in ['A', 'F', 'U']:\n",
    "        price = int(message.price)\n",
    "        shares = int(message.shares)\n",
    "\n",
    "        current_orders[buysell].update({price: shares})\n",
    "        current_orders[buysell], new_order = add_orders(current_orders[buysell], buysell, nlevels)\n",
    "        order_book[buysell][message.timestamp] = new_order\n",
    "\n",
    "    if message.type in ['E', 'C', 'X', 'D', 'U']:\n",
    "        if message.type == 'U':\n",
    "            if not np.isnan(message.shares_replaced):\n",
    "                price = int(message.price_replaced)\n",
    "                shares = -int(message.shares_replaced)\n",
    "        else:\n",
    "            if not np.isnan(message.price):\n",
    "                price = int(message.price)\n",
    "                shares = -int(message.shares)\n",
    "\n",
    "        if price is not None:\n",
    "            current_orders[buysell].update({price: shares})\n",
    "            if current_orders[buysell][price] <= 0:\n",
    "                current_orders[buysell].pop(price)\n",
    "            current_orders[buysell], new_order = add_orders(current_orders[buysell], buysell, nlevels)\n",
    "            order_book[buysell][message.timestamp] = new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:13.367586Z",
     "start_time": "2018-12-25T18:59:13.365257Z"
    }
   },
   "outputs": [],
   "source": [
    "message_counter = pd.Series(message_counter)\n",
    "print(message_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:13.386058Z",
     "start_time": "2018-12-25T18:59:13.368397Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('order_book.h5') as store:\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Book Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:34.898346Z",
     "start_time": "2018-12-25T18:59:13.387216Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    buy = store['{}/buy'.format(stock)].reset_index().drop_duplicates()\n",
    "    sell = store['{}/sell'.format(stock)].reset_index().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price to Decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:35.213809Z",
     "start_time": "2018-12-25T18:59:34.901354Z"
    }
   },
   "outputs": [],
   "source": [
    "buy.price = buy.price.mul(1e-4)\n",
    "sell.price = sell.price.mul(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:42.096414Z",
     "start_time": "2018-12-25T18:59:35.214763Z"
    }
   },
   "outputs": [],
   "source": [
    "percentiles = [.01, .02, .1, .25, .75, .9, .98, .99]\n",
    "pd.concat([buy.price.describe(percentiles=percentiles).to_frame('buy'),\n",
    "           sell.price.describe(percentiles=percentiles).to_frame('sell')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T18:59:44.810646Z",
     "start_time": "2018-12-25T18:59:42.097253Z"
    }
   },
   "outputs": [],
   "source": [
    "buy = buy[buy.price > buy.price.quantile(.01)]\n",
    "sell = sell[sell.price < sell.price.quantile(.99)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buy-Sell Order Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:03.115714Z",
     "start_time": "2018-12-25T19:03:03.109202Z"
    }
   },
   "outputs": [],
   "source": [
    "market_open='0930'\n",
    "market_close = '1600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:37.441700Z",
     "start_time": "2018-12-25T19:03:26.117795Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "hist_kws = {'linewidth': 1, 'alpha': .5}\n",
    "sns.distplot(buy.set_index('timestamp').between_time(market_open, market_close).price, ax=ax, label='Buy', kde=False, hist_kws=hist_kws)\n",
    "sns.distplot(sell.set_index('timestamp').between_time(market_open, market_close).price, ax=ax, label='Sell', kde=False, hist_kws=hist_kws)\n",
    "plt.legend(fontsize=10)\n",
    "plt.title('Limit Order Price Distribution', fontsize=14)\n",
    "ax.set_yticklabels(['{:,}'.format(int(y/1000)) for y in ax.get_yticks().tolist()])\n",
    "ax.set_xticklabels(['${:,}'.format(int(x)) for x in ax.get_xticks().tolist()])\n",
    "plt.xlabel('Price', fontsize=12)\n",
    "plt.ylabel('Shares (\\'000)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/price_distribution', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Book Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:45.701297Z",
     "start_time": "2018-12-25T19:03:45.696600Z"
    }
   },
   "outputs": [],
   "source": [
    "utc_offset = timedelta(hours=4)\n",
    "depth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:48.330392Z",
     "start_time": "2018-12-25T19:03:46.059173Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buy_per_min = (buy\n",
    "               .groupby([pd.Grouper(key='timestamp', freq='Min'), 'price'])\n",
    "               .shares\n",
    "               .sum()\n",
    "               .apply(np.log)\n",
    "               .to_frame('shares')\n",
    "               .reset_index('price')\n",
    "               .between_time(market_open, market_close)\n",
    "               .groupby(level='timestamp', as_index=False, group_keys=False)\n",
    "               .apply(lambda x: x.nlargest(columns='price', n=depth))\n",
    "               .reset_index())\n",
    "buy_per_min.timestamp = buy_per_min.timestamp.add(utc_offset).astype(int)\n",
    "buy_per_min.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:50.748806Z",
     "start_time": "2018-12-25T19:03:48.331693Z"
    }
   },
   "outputs": [],
   "source": [
    "sell_per_min = (sell\n",
    "                .groupby([pd.Grouper(key='timestamp', freq='Min'), 'price'])\n",
    "                .shares\n",
    "                .sum()\n",
    "                .apply(np.log)\n",
    "                .to_frame('shares')\n",
    "                .reset_index('price')\n",
    "                .between_time(market_open, market_close)\n",
    "                .groupby(level='timestamp', as_index=False, group_keys=False)\n",
    "                .apply(lambda x: x.nsmallest(columns='price', n=depth))\n",
    "                .reset_index())\n",
    "\n",
    "sell_per_min.timestamp = sell_per_min.timestamp.add(utc_offset).astype(int)\n",
    "sell_per_min.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:03:51.440194Z",
     "start_time": "2018-12-25T19:03:51.399025Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(order_book_store) as store:\n",
    "    trades = store['{}/trades'.format(stock)]\n",
    "trades.price = trades.price.mul(1e-4)\n",
    "trades = trades[trades.cross == 0].between_time(market_open, market_close)\n",
    "\n",
    "trades_per_min = (trades\n",
    "                  .resample('Min')\n",
    "                  .agg({'price': 'mean', 'shares': 'sum'}))\n",
    "trades_per_min.index = trades_per_min.index.to_series().add(utc_offset).astype(int)\n",
    "trades_per_min.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T19:06:39.328578Z",
     "start_time": "2018-12-25T19:06:37.074213Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "buy_per_min.plot.scatter(x='timestamp',y='price', c='shares', ax=ax, colormap='Blues', colorbar=False, alpha=.25)\n",
    "sell_per_min.plot.scatter(x='timestamp',y='price', c='shares', ax=ax, colormap='Reds', colorbar=False, alpha=.25)\n",
    "trades_per_min.price.plot(figsize=(14, 8), c='k', ax=ax, lw=2, \n",
    "                          title=f'AAPL | {date} | Buy & Sell Limit Order Book | Depth = {depth}')\n",
    "\n",
    "xticks = [datetime.fromtimestamp(ts / 1e9).strftime('%H:%M') for ts in ax.get_xticks()]\n",
    "ax.set_xticklabels(xticks)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Price')\n",
    "\n",
    "# date = pd.to_datetime(date).date()\n",
    "fig.tight_layout()\n",
    "# fig.savefig('figures/order_book', dpi=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
